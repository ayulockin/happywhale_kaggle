{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc2cfa1-0e48-41cd-bc21-7f6619f04659",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f88ef-103a-48b3-b9ac-16bb67a11033",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce2b0cf-4f5b-49fd-87e7-bd478323cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PLATFORM'] = 'GCP' # Kaggle, Colab, Paperspace, Local\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "from model import SimpleSupervisedModel, ArcFaceSupervisedModel, get_feature_extractor\n",
    "from config import get_train_config\n",
    "from data import GetDataloader\n",
    "from utils import ShowBatch, id_generator, get_stratified_k_fold, setup_device, count_data_items\n",
    "from callbacks import GetCallbacks\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d234df-381c-40fa-9bce-b557002ba533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GPU Available ####\n",
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Setup Device for training\n",
    "strategy = setup_device()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af79734d-6a2b-47c3-81b9-b5521aec5d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "# Setup W&B Login\n",
    "try:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "except:\n",
    "    !pip install -qqq wandb\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "else:\n",
    "    from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6949d087-0176-4618-87ef-68a47c0881cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where are we working? -  GCP\n"
     ]
    }
   ],
   "source": [
    "# Setup Platform\n",
    "platform = os.getenv('PLATFORM', None)\n",
    "print('Where are we working? - ', platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a67258-fa87-4678-9430-072bc6f2ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID:  WDEREODW\n"
     ]
    }
   ],
   "source": [
    "# Setup configs\n",
    "args = get_train_config()\n",
    "\n",
    "# Setup experiment id for W&B\n",
    "random_id = id_generator(size=8)\n",
    "args.exp_id = random_id\n",
    "print('Experiment ID: ', args.exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9abf5b-961a-43bf-93cc-b5e6063c795b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49fd7ec3-040d-47d3-b06e-aab3d07e01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_PATH = 'gs://kds-d916c3252bf3bc5b3500b904f05f51ce57c8df85221d11b7711bcda9'\n",
    "GCS_PATH = 'gs://kds-6f96f0bc6a675e5d7d316d604702c92b164fc68a7fe681084b7a873d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77c1d8a1-6413-4d91-b32c-9088fdf39818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kds-6f96f0bc6a675e5d7d316d604702c92b164fc68a7fe681084b7a873d\n",
      "10 10 51033 27956\n"
     ]
    }
   ],
   "source": [
    "train_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-train*.tfrec')))\n",
    "test_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-test*.tfrec')))\n",
    "print(GCS_PATH)\n",
    "print(len(train_files), len(test_files), count_data_items(train_files), count_data_items(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139ea53-07f3-4d78-a024-0a11930d8235",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76c4fabe-dc94-4853-ba9c-b524453acd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def data_augment(image, label):\n",
    "    return image, label\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, [args.image_height, args.image_width])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string), # Name of image\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # Image tensors\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64), # Individual ID\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    \n",
    "    image_name = example['image_name']\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    \n",
    "    return image_name, image, label\n",
    "\n",
    "\n",
    "def load_dataset(filenames, ordered = False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f956f82-80fb-41e8-8cac-87cfb9aae8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(filenames, \n",
    "                   type='train', # valid, eval, test\n",
    "                   get_targets=True, \n",
    "                   get_names=False):\n",
    "    \n",
    "    if type=='train':\n",
    "        order = False\n",
    "    else:\n",
    "        order = True\n",
    "        \n",
    "    dataloader = load_dataset(filenames, ordered=order)\n",
    "\n",
    "    if type=='train':\n",
    "        dataloader = dataloader.shuffle(args.batch_size*100)\n",
    "        dataloader = dataloader.map(lambda image_name, image, label: (image, label))\n",
    "        dataloader = dataloader.map(data_augment, num_parallel_calls=AUTO)\n",
    "        dataloader = dataloader.repeat()\n",
    "    elif type=='valid':\n",
    "        dataloader = dataloader.map(lambda image_name, image, label: (image, label))\n",
    "    elif type=='eval':\n",
    "        dataloader = dataloader.map(lambda image_name, image, label: (image, label))\n",
    "        if not get_targets:\n",
    "            dataloader = dataloader.map(lambda image, label: image)\n",
    "    elif type=='test':\n",
    "        dataloader = dataloader.map(lambda image_name, image, label: (image_name, image))\n",
    "        if not get_names:\n",
    "            dataloader = dataloader.map(lambda image_name, image: image)\n",
    "\n",
    "    dataloader = dataloader.batch(args.batch_size)\n",
    "    dataloader = dataloader.prefetch(AUTO)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb66bc43-53a7-49ba-8d6b-58432d3424c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = get_dataloader(train_files[0],\n",
    "                             type='train', # valid, eval, test\n",
    "                             get_targets=True, \n",
    "                             get_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ca76c-77fa-4234-b67c-9de120456e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs, sample_labels = next(iter(trainloader))\n",
    "show_batch = ShowBatch(args)\n",
    "show_batch.show_batch(sample_imgs, sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34308cd-a049-450c-ad14-efac92f1546e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
